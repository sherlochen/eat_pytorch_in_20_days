{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea02e6fd",
   "metadata": {},
   "source": [
    "# Mac M1 èŠ¯ç‰‡åŠ é€ŸpytorchæŒ‡å—"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86314b9",
   "metadata": {},
   "source": [
    "å‚è€ƒæ–‡ç« :\n",
    "\n",
    "ã€ŠPyTorchå®£å¸ƒæ”¯æŒè‹¹æœM1èŠ¯ç‰‡GPUåŠ é€Ÿï¼šè®­ç»ƒå¿«6å€ï¼Œæ¨ç†æå‡21å€ã€‹ https://zhuanlan.zhihu.com/p/516920793\n",
    "\n",
    "ã€ŠMacbookM1èŠ¯ç‰‡æ·±åº¦å­¦ä¹ ç¯å¢ƒé…ç½®æœ€å…¨æ•™ç¨‹ï¼šç®€æ˜å®‰è£…å¼€å‘TensorFlowä¸PyTorchã€‹https://zhuanlan.zhihu.com/p/483551833\n",
    "\n",
    "ã€Šä¸€æ–‡è§£é‡Šconda,pip,anaconda,miniconda,miniforgeã€‹ https://zhuanlan.zhihu.com/p/518926990\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec75498",
   "metadata": {},
   "source": [
    "## ä¸€ï¼ŒåŠ é€ŸåŸç†\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27edfe53",
   "metadata": {},
   "source": [
    "* Question1ï¼ŒMac M1èŠ¯ç‰‡ ä¸ºä»€ä¹ˆå¯ä»¥ç”¨æ¥åŠ é€Ÿ pytorchï¼Ÿ\n",
    "\n",
    "å› ä¸º Mac M1èŠ¯ç‰‡ä¸æ˜¯ä¸€ä¸ªå•çº¯çš„ä¸€ä¸ªCPUèŠ¯ç‰‡ï¼Œè€Œæ˜¯åŒ…æ‹¬äº†CPU(ä¸­å¤®å¤„ç†å™¨)ï¼ŒGPU(å›¾å½¢å¤„ç†å™¨)ï¼ŒNPU(ç¥ç»ç½‘ç»œå¼•æ“)ï¼Œä»¥åŠç»Ÿä¸€å†…å­˜å•å…ƒç­‰ä¼—å¤šç»„ä»¶çš„ä¸€å—é›†æˆèŠ¯ç‰‡ã€‚ç”±äºMac M1èŠ¯ç‰‡é›†æˆäº†GPUç»„ä»¶ï¼Œæ‰€ä»¥å¯ä»¥ç”¨æ¥åŠ é€Ÿpytorch.\n",
    "\n",
    "* Question2ï¼ŒMac M1èŠ¯ç‰‡ ä¸ŠGPUçš„çš„æ˜¾å­˜æœ‰å¤šå¤§ï¼Ÿ\n",
    "\n",
    "Mac M1èŠ¯ç‰‡çš„CPUå’ŒGPUä½¿ç”¨ç»Ÿä¸€çš„å†…å­˜å•å…ƒã€‚æ‰€ä»¥Mac M1èŠ¯ç‰‡çš„èƒ½ä½¿ç”¨çš„æ˜¾å­˜å¤§å°å°±æ˜¯ Mac ç”µè„‘çš„å†…å­˜å¤§å°ã€‚\n",
    "\n",
    "* Question3ï¼Œä½¿ç”¨Mac M1èŠ¯ç‰‡åŠ é€Ÿ pytorch éœ€è¦å®‰è£… cudaåç«¯å—ï¼Ÿ\n",
    "\n",
    "ä¸éœ€è¦ï¼Œcudaæ˜¯é€‚é…nvidiaçš„GPUçš„ï¼ŒMac M1èŠ¯ç‰‡ä¸­çš„GPUé€‚é…çš„åŠ é€Ÿåç«¯æ˜¯mpsï¼Œåœ¨Macå¯¹åº”æ“ä½œç³»ç»Ÿä¸­å·²ç»å…·å¤‡ï¼Œæ— éœ€å•ç‹¬å®‰è£…ã€‚åªéœ€è¦å®‰è£…é€‚é…çš„pytorchå³å¯ã€‚\n",
    "\n",
    "* Question4ï¼Œä¸ºä»€ä¹ˆæœ‰äº›å¯ä»¥åœ¨Mac IntelèŠ¯ç‰‡ç”µè„‘å®‰è£…çš„è½¯ä»¶ä¸èƒ½åœ¨Mac M1èŠ¯ç‰‡ç”µè„‘ä¸Šå®‰è£…ï¼Ÿ\n",
    "\n",
    "Mac M1èŠ¯ç‰‡ä¸ºäº†è¿½æ±‚é«˜æ€§èƒ½å’ŒèŠ‚èƒ½ï¼Œåœ¨åº•å±‚è®¾è®¡ä¸Šä½¿ç”¨çš„æ˜¯ä¸€ç§å«åšarmæ¶æ„çš„ç²¾ç®€æŒ‡ä»¤é›†ï¼Œä¸åŒäºIntelç­‰å¸¸ç”¨CPUèŠ¯ç‰‡é‡‡ç”¨çš„x86æ¶æ„å®Œæ•´æŒ‡ä»¤é›†ã€‚æ‰€ä»¥æœ‰äº›åŸºäºx86æŒ‡ä»¤é›†å¼€å‘çš„è½¯ä»¶ä¸èƒ½ç›´æ¥åœ¨Mac M1èŠ¯ç‰‡ç”µè„‘ä¸Šä½¿ç”¨ã€‚\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/008vxvgGgy1h8k14eaodhj30vf0u0juj.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a39248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c17aa29",
   "metadata": {},
   "source": [
    "## äºŒï¼Œç¯å¢ƒé…ç½®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8639e6db",
   "metadata": {},
   "source": [
    "\n",
    "0ï¼Œæ£€æŸ¥macå‹å·\n",
    "\n",
    "ç‚¹å‡»æ¡Œé¢å·¦ä¸Šè§’macå›¾æ ‡â€”â€”>å…³äºæœ¬æœºâ€”â€”>æ¦‚è§ˆï¼Œç¡®å®šæ˜¯m1èŠ¯ç‰‡ï¼Œäº†è§£å†…å­˜å¤§å°(æœ€å¥½æœ‰16Gä»¥ä¸Šï¼Œ8Gå¯èƒ½ä¸å¤ªå¤Ÿç”¨)ã€‚\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/008vxvgGgy1h8k27lhkrhj30vo0fgmye.jpg) \n",
    "\n",
    "\n",
    "\n",
    "1ï¼Œä¸‹è½½ miniforge3 (miniforge3å¯ä»¥ç†è§£æˆ miniconda/annoconda çš„ç¤¾åŒºç‰ˆï¼Œæä¾›äº†æ›´ç¨³å®šçš„å¯¹M1èŠ¯ç‰‡çš„æ”¯æŒ)\n",
    "\n",
    "https://github.com/conda-forge/miniforge/#download\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/008vxvgGgy1h8k24engoxj311a0ki780.jpg)\n",
    "\n",
    "å¤‡æ³¨: annoconda åœ¨ 2022å¹´5æœˆå¼€å§‹ä¹Ÿå‘å¸ƒäº†å¯¹ mac m1èŠ¯ç‰‡çš„å®˜æ–¹æ”¯æŒï¼Œä½†è¿˜æ˜¯æ¨èç¤¾åŒºå‘å¸ƒçš„miniforge3ï¼Œå¼€æºä¸”æ›´åŠ ç¨³å®šã€‚\n",
    "\n",
    "\n",
    "2ï¼Œå®‰è£… miniforge3\n",
    "\n",
    "```bash\n",
    "chmod +x ~/Downloads/Miniforge3-MacOSX-arm64.sh\n",
    "sh ~/Downloads/Miniforge3-MacOSX-arm64.sh\n",
    "source ~/miniforge3/bin/activate\n",
    "```\n",
    "\n",
    "\n",
    "3ï¼Œå®‰è£… pytorch (v1.12ç‰ˆæœ¬å·²ç»æ­£å¼æ”¯æŒäº†ç”¨äºmac m1èŠ¯ç‰‡gpuåŠ é€Ÿçš„mpsåç«¯ã€‚)\n",
    "\n",
    "```\n",
    "pip install torch>=1.12 -i https://pypi.tuna.tsinghua.edu.cn/simple \n",
    "\n",
    "```\n",
    "\n",
    "4ï¼Œæµ‹è¯•ç¯å¢ƒ\n",
    "\n",
    "```python\n",
    "import torch \n",
    "\n",
    "print(torch.backends.mps.is_available()) \n",
    "print(torch.backends.mps.is_built())\n",
    "```\n",
    "å¦‚æœè¾“å‡ºéƒ½æ˜¯Trueçš„è¯ï¼Œé‚£ä¹ˆæ­å–œä½ é…ç½®æˆåŠŸäº†ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab870fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d45bae58",
   "metadata": {},
   "source": [
    "## ä¸‰ï¼ŒèŒƒä¾‹ä»£ç "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8c8fa6",
   "metadata": {},
   "source": [
    "ä¸‹é¢ä»¥mnistæ‰‹å†™æ•°å­—è¯†åˆ«ä¸ºä¾‹ï¼Œæ¼”ç¤ºä½¿ç”¨mac M1èŠ¯ç‰‡GPUçš„mpsåç«¯æ¥åŠ é€Ÿpytorchçš„å®Œæ•´æµç¨‹ã€‚\n",
    "\n",
    "æ ¸å¿ƒæ“ä½œéå¸¸ç®€å•ï¼Œå’Œä½¿ç”¨cudaç±»ä¼¼ï¼Œè®­ç»ƒå‰æŠŠæ¨¡å‹å’Œæ•°æ®éƒ½ç§»åŠ¨åˆ°torch.device(\"mps\")å°±å¯ä»¥äº†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c32f563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "  (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (linear2): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "================================================================================2024-09-29 21:04:07\n",
      "Epoch 1 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                       | 0/469 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 309, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/opt/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torchvision/datasets/mnist.py\", line 146, in __getitem__\n    img = self.transform(img)\n          ^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n    img = t(img)\n          ^^^^^^\n  File \"/opt/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torchvision/transforms/transforms.py\", line 137, in __call__\n    return F.to_tensor(pic)\n           ^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torchvision/transforms/functional.py\", line 168, in to_tensor\n    img = torch.from_numpy(np.array(pic, mode_to_nptype.get(pic.mode, np.uint8), copy=True))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: expected np.ndarray (got numpy.ndarray)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 120\u001b[0m\n\u001b[1;32m    117\u001b[0m loop \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28menumerate\u001b[39m(dl_train), total \u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dl_train),ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m    118\u001b[0m train_metrics_dict \u001b[38;5;241m=\u001b[39m deepcopy(metrics_dict) \n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m loop: \n\u001b[1;32m    122\u001b[0m     features,labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;66;03m# =========================ç§»åŠ¨æ•°æ®åˆ°mpsä¸Š==============================\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deeplearning/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1344\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1343\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1370\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1370\u001b[0m     data\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/_utils.py:706\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 706\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 309, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/opt/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torchvision/datasets/mnist.py\", line 146, in __getitem__\n    img = self.transform(img)\n          ^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n    img = t(img)\n          ^^^^^^\n  File \"/opt/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torchvision/transforms/transforms.py\", line 137, in __call__\n    return F.to_tensor(pic)\n           ^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torchvision/transforms/functional.py\", line 168, in to_tensor\n    img = torch.from_numpy(np.array(pic, mode_to_nptype.get(pic.mode, np.uint8), copy=True))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: expected np.ndarray (got numpy.ndarray)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "import torchvision \n",
    "from torchvision import transforms \n",
    "import torch.nn.functional as F \n",
    "\n",
    "\n",
    "import os,sys,time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime \n",
    "from tqdm import tqdm \n",
    "from copy import deepcopy\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "\n",
    "def printlog(info):\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n",
    "    print(str(info)+\"\\n\")\n",
    "    \n",
    "    \n",
    "#================================================================================\n",
    "# ä¸€ï¼Œå‡†å¤‡æ•°æ®\n",
    "#================================================================================\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "ds_train = torchvision.datasets.MNIST(root=\"mnist/\",train=True,download=True,transform=transform)\n",
    "ds_val = torchvision.datasets.MNIST(root=\"mnist/\",train=False,download=True,transform=transform)\n",
    "\n",
    "dl_train =  torch.utils.data.DataLoader(ds_train, batch_size=128, shuffle=True, num_workers=2)\n",
    "dl_val =  torch.utils.data.DataLoader(ds_val, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "#================================================================================\n",
    "# äºŒï¼Œå®šä¹‰æ¨¡å‹\n",
    "#================================================================================\n",
    "\n",
    "\n",
    "def create_net():\n",
    "    net = nn.Sequential()\n",
    "    net.add_module(\"conv1\",nn.Conv2d(in_channels=1,out_channels=64,kernel_size = 3))\n",
    "    net.add_module(\"pool1\",nn.MaxPool2d(kernel_size = 2,stride = 2))\n",
    "    net.add_module(\"conv2\",nn.Conv2d(in_channels=64,out_channels=512,kernel_size = 3))\n",
    "    net.add_module(\"pool2\",nn.MaxPool2d(kernel_size = 2,stride = 2))\n",
    "    net.add_module(\"dropout\",nn.Dropout2d(p = 0.1))\n",
    "    net.add_module(\"adaptive_pool\",nn.AdaptiveMaxPool2d((1,1)))\n",
    "    net.add_module(\"flatten\",nn.Flatten())\n",
    "    net.add_module(\"linear1\",nn.Linear(512,1024))\n",
    "    net.add_module(\"relu\",nn.ReLU())\n",
    "    net.add_module(\"linear2\",nn.Linear(1024,10))\n",
    "    return net\n",
    "\n",
    "net = create_net()\n",
    "print(net)\n",
    "\n",
    "# è¯„ä¼°æŒ‡æ ‡\n",
    "class Accuracy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.correct = nn.Parameter(torch.tensor(0.0),requires_grad=False)\n",
    "        self.total = nn.Parameter(torch.tensor(0.0),requires_grad=False)\n",
    "\n",
    "    def forward(self, preds: torch.Tensor, targets: torch.Tensor):\n",
    "        preds = preds.argmax(dim=-1)\n",
    "        m = (preds == targets).sum()\n",
    "        n = targets.shape[0] \n",
    "        self.correct += m \n",
    "        self.total += n\n",
    "        \n",
    "        return m/n\n",
    "\n",
    "    def compute(self):\n",
    "        return self.correct.float() / self.total \n",
    "    \n",
    "    def reset(self):\n",
    "        self.correct -= self.correct\n",
    "        self.total -= self.total\n",
    "        \n",
    "#================================================================================\n",
    "# ä¸‰ï¼Œè®­ç»ƒæ¨¡å‹\n",
    "#================================================================================     \n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer= torch.optim.Adam(net.parameters(),lr = 0.01)   \n",
    "metrics_dict = nn.ModuleDict({\"acc\":Accuracy()})\n",
    "\n",
    "\n",
    "# =========================ç§»åŠ¨æ¨¡å‹åˆ°mpsä¸Š==============================\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "loss_fn.to(device)\n",
    "metrics_dict.to(device)\n",
    "# ====================================================================\n",
    "\n",
    "\n",
    "epochs = 20 \n",
    "ckpt_path='checkpoint.pt'\n",
    "\n",
    "#early_stoppingç›¸å…³è®¾ç½®\n",
    "monitor=\"val_acc\"\n",
    "patience=5\n",
    "mode=\"max\"\n",
    "\n",
    "history = {}\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    printlog(\"Epoch {0} / {1}\".format(epoch, epochs))\n",
    "\n",
    "    # 1ï¼Œtrain -------------------------------------------------  \n",
    "    net.train()\n",
    "    \n",
    "    total_loss,step = 0,0\n",
    "    \n",
    "    loop = tqdm(enumerate(dl_train), total =len(dl_train),ncols=100)\n",
    "    train_metrics_dict = deepcopy(metrics_dict) \n",
    "    \n",
    "    for i, batch in loop: \n",
    "        \n",
    "        features,labels = batch\n",
    "        \n",
    "        # =========================ç§»åŠ¨æ•°æ®åˆ°mpsä¸Š==============================\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # ====================================================================\n",
    "        \n",
    "        #forward\n",
    "        preds = net(features)\n",
    "        loss = loss_fn(preds,labels)\n",
    "        \n",
    "        #backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        #metrics\n",
    "        step_metrics = {\"train_\"+name:metric_fn(preds, labels).item() \n",
    "                        for name,metric_fn in train_metrics_dict.items()}\n",
    "        \n",
    "        step_log = dict({\"train_loss\":loss.item()},**step_metrics)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        step+=1\n",
    "        if i!=len(dl_train)-1:\n",
    "            loop.set_postfix(**step_log)\n",
    "        else:\n",
    "            epoch_loss = total_loss/step\n",
    "            epoch_metrics = {\"train_\"+name:metric_fn.compute().item() \n",
    "                             for name,metric_fn in train_metrics_dict.items()}\n",
    "            epoch_log = dict({\"train_loss\":epoch_loss},**epoch_metrics)\n",
    "            loop.set_postfix(**epoch_log)\n",
    "\n",
    "            for name,metric_fn in train_metrics_dict.items():\n",
    "                metric_fn.reset()\n",
    "                \n",
    "    for name, metric in epoch_log.items():\n",
    "        history[name] = history.get(name, []) + [metric]\n",
    "        \n",
    "\n",
    "    # 2ï¼Œvalidate -------------------------------------------------\n",
    "    net.eval()\n",
    "    \n",
    "    total_loss,step = 0,0\n",
    "    loop = tqdm(enumerate(dl_val), total =len(dl_val),ncols=100)\n",
    "    \n",
    "    val_metrics_dict = deepcopy(metrics_dict) \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in loop: \n",
    "\n",
    "            features,labels = batch\n",
    "            \n",
    "            # =========================ç§»åŠ¨æ•°æ®åˆ°mpsä¸Š==============================\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # ====================================================================\n",
    "            \n",
    "            #forward\n",
    "            preds = net(features)\n",
    "            loss = loss_fn(preds,labels)\n",
    "\n",
    "            #metrics\n",
    "            step_metrics = {\"val_\"+name:metric_fn(preds, labels).item() \n",
    "                            for name,metric_fn in val_metrics_dict.items()}\n",
    "\n",
    "            step_log = dict({\"val_loss\":loss.item()},**step_metrics)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            step+=1\n",
    "            if i!=len(dl_val)-1:\n",
    "                loop.set_postfix(**step_log)\n",
    "            else:\n",
    "                epoch_loss = (total_loss/step)\n",
    "                epoch_metrics = {\"val_\"+name:metric_fn.compute().item() \n",
    "                                 for name,metric_fn in val_metrics_dict.items()}\n",
    "                epoch_log = dict({\"val_loss\":epoch_loss},**epoch_metrics)\n",
    "                loop.set_postfix(**epoch_log)\n",
    "\n",
    "                for name,metric_fn in val_metrics_dict.items():\n",
    "                    metric_fn.reset()\n",
    "                    \n",
    "    epoch_log[\"epoch\"] = epoch           \n",
    "    for name, metric in epoch_log.items():\n",
    "        history[name] = history.get(name, []) + [metric]\n",
    "\n",
    "    # 3ï¼Œearly-stopping -------------------------------------------------\n",
    "    arr_scores = history[monitor]\n",
    "    best_score_idx = np.argmax(arr_scores) if mode==\"max\" else np.argmin(arr_scores)\n",
    "    if best_score_idx==len(arr_scores)-1:\n",
    "        torch.save(net.state_dict(),ckpt_path)\n",
    "        print(\"<<<<<< reach best {0} : {1} >>>>>>\".format(monitor,\n",
    "             arr_scores[best_score_idx]),file=sys.stderr)\n",
    "    if len(arr_scores)-best_score_idx>patience:\n",
    "        print(\"<<<<<< {} without improvement in {} epoch, early stopping >>>>>>\".format(\n",
    "            monitor,patience),file=sys.stderr)\n",
    "        break \n",
    "    net.load_state_dict(torch.load(ckpt_path))\n",
    "    \n",
    "dfhistory = pd.DataFrame(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b7fdf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "817c0ca1-dfdc-42f3-a660-b34b096ac2d4",
   "metadata": {},
   "source": [
    "## å››ï¼Œä½¿ç”¨torchkerasæ”¯æŒMac M1èŠ¯ç‰‡åŠ é€Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8527a167-02c8-4980-ac1d-ecece961616b",
   "metadata": {},
   "source": [
    "3.3.0ä»¥ä¸Šçš„torchkerasç‰ˆæœ¬ä¸­å¼•å…¥äº†å¯¹ mac m1èŠ¯ç‰‡çš„æ”¯æŒï¼Œå½“å­˜åœ¨å¯ç”¨çš„ mac m1èŠ¯ç‰‡/ GPU æ—¶ï¼Œä¼šé»˜è®¤ä½¿ç”¨å®ƒä»¬è¿›è¡ŒåŠ é€Ÿï¼Œæ— éœ€åšä»»ä½•é…ç½®ã€‚\n",
    "\n",
    "ä½¿ç”¨èŒƒä¾‹å¦‚ä¸‹ã€‚ğŸ˜‹ğŸ˜‹ğŸ˜‹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96be06af-186c-4d48-b15c-3a0f79f8ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U torchkeras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa97081-8940-41c3-9283-ea0c5444efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torchkeras #Attention this line \n",
    "\n",
    "\n",
    "#================================================================================\n",
    "# ä¸€ï¼Œå‡†å¤‡æ•°æ®\n",
    "#================================================================================\n",
    "\n",
    "import torchvision \n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "ds_train = torchvision.datasets.MNIST(root=\"mnist/\",train=True,download=True,transform=transform)\n",
    "ds_val = torchvision.datasets.MNIST(root=\"mnist/\",train=False,download=True,transform=transform)\n",
    "dl_train =  torch.utils.data.DataLoader(ds_train, batch_size=128, shuffle=True, num_workers=2)\n",
    "dl_val =  torch.utils.data.DataLoader(ds_val, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "for features,labels in dl_train:\n",
    "    break \n",
    "\n",
    "#================================================================================\n",
    "# äºŒï¼Œå®šä¹‰æ¨¡å‹\n",
    "#================================================================================\n",
    "\n",
    "\n",
    "def create_net():\n",
    "    net = nn.Sequential()\n",
    "    net.add_module(\"conv1\",nn.Conv2d(in_channels=1,out_channels=64,kernel_size = 3))\n",
    "    net.add_module(\"pool1\",nn.MaxPool2d(kernel_size = 2,stride = 2))\n",
    "    net.add_module(\"conv2\",nn.Conv2d(in_channels=64,out_channels=512,kernel_size = 3))\n",
    "    net.add_module(\"pool2\",nn.MaxPool2d(kernel_size = 2,stride = 2))\n",
    "    net.add_module(\"dropout\",nn.Dropout2d(p = 0.1))\n",
    "    net.add_module(\"adaptive_pool\",nn.AdaptiveMaxPool2d((1,1)))\n",
    "    net.add_module(\"flatten\",nn.Flatten())\n",
    "    net.add_module(\"linear1\",nn.Linear(512,1024))\n",
    "    net.add_module(\"relu\",nn.ReLU())\n",
    "    net.add_module(\"linear2\",nn.Linear(1024,10))\n",
    "    return net\n",
    "\n",
    "net = create_net()\n",
    "print(net)\n",
    "\n",
    "# è¯„ä¼°æŒ‡æ ‡\n",
    "class Accuracy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.correct = nn.Parameter(torch.tensor(0.0),requires_grad=False)\n",
    "        self.total = nn.Parameter(torch.tensor(0.0),requires_grad=False)\n",
    "\n",
    "    def forward(self, preds: torch.Tensor, targets: torch.Tensor):\n",
    "        preds = preds.argmax(dim=-1)\n",
    "        m = (preds == targets).sum()\n",
    "        n = targets.shape[0] \n",
    "        self.correct += m \n",
    "        self.total += n\n",
    "        \n",
    "        return m/n\n",
    "\n",
    "    def compute(self):\n",
    "        return self.correct.float() / self.total \n",
    "    \n",
    "    def reset(self):\n",
    "        self.correct -= self.correct\n",
    "        self.total -= self.total\n",
    "        \n",
    "\n",
    "\n",
    "#================================================================================\n",
    "# ä¸‰ï¼Œè®­ç»ƒæ¨¡å‹\n",
    "#================================================================================\n",
    "\n",
    "model = torchkeras.KerasModel(net,\n",
    "      loss_fn = nn.CrossEntropyLoss(),\n",
    "      optimizer= torch.optim.Adam(net.parameters(),lr=0.001),\n",
    "      metrics_dict = {\"acc\":Accuracy()}\n",
    "    )\n",
    "\n",
    "from torchkeras import summary\n",
    "summary(model,input_data=features);\n",
    "\n",
    "\n",
    "# if gpu/mps is available, will auto use it, otherwise cpu will be used.\n",
    "\n",
    "dfhistory=model.fit(train_data=dl_train, \n",
    "                    val_data=dl_val, \n",
    "                    epochs=15, \n",
    "                    patience=5, \n",
    "                    monitor=\"val_acc\",\n",
    "                    mode=\"max\",\n",
    "                    ckpt_path='checkpoint')\n",
    "\n",
    "#================================================================================\n",
    "# å››ï¼Œè¯„ä¼°æ¨¡å‹\n",
    "#================================================================================\n",
    "\n",
    "model.evaluate(dl_val)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27c94a1-8df1-4c2e-a131-578588792967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9f63aa-2dc8-4004-bbbf-062b42aab800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddbfb751",
   "metadata": {},
   "source": [
    "## äº”ï¼ŒM1èŠ¯ç‰‡ä¸CPUå’ŒNvidia GPUé€Ÿåº¦å¯¹æ¯”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77f25cd-53a2-44a3-b308-9cafa045ee60",
   "metadata": {},
   "source": [
    "ä½¿ç”¨ä»¥ä¸Šä»£ç ä½œä¸ºèŒƒä¾‹ï¼Œåˆ†åˆ«åœ¨CPU, mac m1èŠ¯ç‰‡ï¼Œä»¥åŠNvidia GPUä¸Š è¿è¡Œã€‚\n",
    "\n",
    "å¾—åˆ°çš„è¿è¡Œé€Ÿåº¦æˆªå›¾å¦‚ä¸‹ï¼š\n",
    "\n",
    "çº¯CPUè·‘æ•ˆæœ\n",
    "![](https://tva1.sinaimg.cn/large/008vxvgGgy1h8pu8qudibj318i0d0n06.jpg)\n",
    "\n",
    "Mac M1 èŠ¯ç‰‡åŠ é€Ÿæ•ˆæœ\n",
    "![](https://tva1.sinaimg.cn/large/008vxvgGgy1h8pubdxbrkj318u0eywhq.jpg)\n",
    "\n",
    "\n",
    "Tesla P100 GPUåŠ é€Ÿæ•ˆæœ\n",
    "![](https://tva1.sinaimg.cn/large/008vxvgGgy1h8pu9epg15j319i0dcn0c.jpg)\n",
    "\n",
    "\n",
    "çº¯CPUè·‘ä¸€ä¸ªepochå¤§çº¦æ˜¯3min 18sã€‚\n",
    "\n",
    "ä½¿ç”¨mac m1èŠ¯ç‰‡åŠ é€Ÿï¼Œä¸€ä¸ªepochå¤§çº¦æ˜¯33 sï¼Œç›¸æ¯”CPUè·‘ï¼ŒåŠ é€Ÿçº¦6å€ã€‚\n",
    "\n",
    "ä½¿ç”¨Nvidia Tesla P100 GPUåŠ é€Ÿï¼Œä¸€ä¸ªepochå¤§çº¦æ˜¯ 8sï¼Œç›¸æ¯”CPUè·‘ï¼ŒåŠ é€Ÿçº¦25å€ã€‚\n",
    "\n",
    "è¿™å’Œpytorchå®˜ç½‘æ˜¾ç¤ºçš„è®­ç»ƒè¿‡ç¨‹å¹³å‡åŠ é€Ÿ7å€ç›¸å½“ã€‚\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/008vxvgGgy1h8putb28ivj30zk0lwq4j.jpg)\n",
    "\n",
    "æ•´ä½“æ¥è¯´Mac M1èŠ¯ç‰‡å¯¹ æ·±åº¦å­¦ä¹ è®­ç»ƒè¿‡ç¨‹çš„åŠ é€Ÿè¿˜æ˜¯éå¸¸æ˜¾è‘—çš„ï¼Œé€šå¸¸è¾¾åˆ°5åˆ°7å€å·¦å³ã€‚\n",
    "\n",
    "ä¸è¿‡ç›®å‰çœ‹å’Œä¼ä¸šä¸­æœ€å¸¸ä½¿ç”¨çš„é«˜ç«¯çš„Tesla P100 GPUç›¸æ¯”ï¼Œè¿˜æ˜¯æœ‰2åˆ°4å€çš„è®­ç»ƒé€Ÿåº¦å·®å¼‚ï¼Œå¯ä»¥è§†åšä¸€ä¸ªminiç‰ˆçš„GPUå§ã€‚\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
